{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "collapsed": true,
        "id": "NwLuCCurJJY7",
        "outputId": "ab4939fe-f20c-435a-fe18-bfe64fb77971"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\" REQUIREMENTS :\\nThe RAG application should :\\n1. Provide answers to questions based on the document's content.\\n2. Print the retrieved content from the document that was used to generate\\xa0these\\xa0answers.\\n\""
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Assessment submitted by Fiaz S Mohammad\n",
        "# Candidate assessment for building a Retreival-Augmented Generation(RAG) application\n",
        "\n",
        "\n",
        "# OBJECTIVE : The goal of this assessment is to build a retrieval-augmented generation(RAG) application. This application should be able to read and comprehend the content of a provided PDF document(in this case Onepane.pdf) and accurately answer questions based in the document's content.\n",
        "''' REQUIREMENTS :\n",
        "The RAG application should :\n",
        "1. Provide answers to questions based on the document's content.\n",
        "2. Print the retrieved content from the document that was used to generate these answers.\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 616
        },
        "collapsed": true,
        "id": "-FmQVQvsJl57",
        "outputId": "af906582-4406-4ec9-8700-a1e0aa5bc083"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: PyMuPDF in /usr/local/lib/python3.10/dist-packages (1.24.7)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Collecting openai==0.28\n",
            "  Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (4.66.4)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (3.9.5)\n",
            "Requirement already satisfied: PyMuPDFb==1.24.6 in /usr/local/lib/python3.10/dist-packages (from PyMuPDF) (1.24.6)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2024.7.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (4.0.3)\n",
            "Installing collected packages: openai\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.35.14\n",
            "    Uninstalling openai-1.35.14:\n",
            "      Successfully uninstalled openai-1.35.14\n",
            "Successfully installed openai-0.28.0\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "bf11bc41cbc34fc3900a45d55d852b53",
              "pip_warning": {
                "packages": [
                  "openai"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip install PyMuPDF scikit-learn openai==0.28 #Installing the required libraries : 1.PyMuPDF - For data extraction from the pdf 2. scikit-learn - For TF-IDF Vectorization and cosine similarity. 3. Openai - To use LLM- ChatGPT 3.5\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6fop4NLfJu5y",
        "outputId": "2b0a527a-5378-4d9f-b107-65a650c29e42"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Retrieved Content:  \n",
            " \n",
            " \n",
            "   Onepane.ai \n",
            "About us \n",
            "Welcome to Onepane, your trusted partner in revolutionizing the way you \n",
            "manage and optimize your cloud resources. Onepane is a cutting-edge \n",
            "SaaS software product designed to empower businesses across various \n",
            "cloud platforms. Our mission is to provide you with the tools and insights \n",
            "necessary to harness the full potential of your cloud infrastructure. \n",
            "What is onepane? \n",
            "Onepane employs intelligent algorithms to suggest and enforce \n",
            "standardized naming conventions for your cloud resources. It also allows \n",
            "you to set up smart tags based on specific criteria, making resource \n",
            "management and tracking more efficient. \n",
            "By unifying incidents across cloud environments, Onepane provides a \n",
            "centralized platform to manage and resolve incidents more efficiently. The \n",
            "enhanced visibility into resources helps in diagnosing issues and reducing \n",
            "downtime. \n",
            "Onepane offers a comprehensive dashboard that provides real-time \n",
            "insights into your cloud resources' status, usage, and performance. This \n",
            "visibility helps in making informed decisions regarding resource allocation \n",
            "and optimization. \n",
            "why onepane ? \n",
            "Reduce your down time with help of AI-Powered Root cause analysis. \n",
            "Efficiently allocate cloud resources with Onepane's resource allocation \n",
            "optimization feature, which enables you to make the most of your cloud \n",
            "resources, striking the right balance between cost saving and operational \n",
            "efficiency.   \n",
            "With Onepane, you can effortlessly guarantee consistency and regulatory \n",
            "alignment of your cloud by enforcing standardized naming and tagging \n",
            "practices. The resulting compliance visibility makes resource management \n",
            "easy.   \n",
            "Organizations have multiple tools to manage incidents (monitoring tool, \n",
            "APM, and other tools). Onepane consolidates alerts, and resource info \n",
            "from all the tools to create incidents. The incidents are then mapped to the \n",
            "right resources, helping teams accelerate incident resolution   \n",
            "How onepane does things ? \n",
            "\n",
            "Answer: Onepane is a valuable tool that can significantly benefit businesses by providing intelligent solutions for managing and optimizing cloud resources. It simplifies resource management by suggesting and enforcing standardized naming conventions, setting up smart tags, and offering real-time insights through a comprehensive dashboard. Additionally, Onepane helps reduce downtime by utilizing AI-powered root cause analysis, optimizes resource allocation for cost savings and operational efficiency, and ensures consistency and regulatory alignment through standardized practices. By consolidating alerts and resource information from various tools, Onepane streamlines incident resolution processes, ultimately helping teams work more efficiently and effectively.\n"
          ]
        }
      ],
      "source": [
        "#Code snippet for RAG :\n",
        "\n",
        "#Importing the required libraries.....\n",
        "import fitz  # PyMuPDF\n",
        "import openai\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def extract_text_from_pdf(pdf_path):                 #This code snippet is used to extract and return the text content from each page of a PDF document.\n",
        "    text = []\n",
        "    doc = fitz.open(pdf_path)\n",
        "    for page_num in range(doc.page_count):\n",
        "        page = doc.load_page(page_num)\n",
        "        text.append(page.get_text())\n",
        "    return text\n",
        "\n",
        "def retrieve_relevant_section(text, query, top_n=1):      #This code snippet is used to identify and return the most relevant sections of text from a list based on their similarity to a query, using TF-IDF vectorization and cosine similarity.\n",
        "    tfidf_vectorizer = TfidfVectorizer().fit_transform(text)\n",
        "    query_tfidf = TfidfVectorizer().fit(text).transform([query])\n",
        "    cosine_similarities = cosine_similarity(query_tfidf, tfidf_vectorizer).flatten()\n",
        "    related_docs_indices = cosine_similarities.argsort()[:-top_n-1:-1]\n",
        "    return [text[i] for i in related_docs_indices]\n",
        "\n",
        "def generate_answer(openai_api_key, query, context):     #This code snippet is used to generate an answer to a query based on provided context by calling the OpenAI API using the gpt-3.5-turbo model, and then returning the generated answer.\n",
        "    openai.api_key = openai_api_key\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "            {\"role\": \"user\", \"content\": f\"Context: {context}\\n\\nQuestion: {query}\\nAnswer:\"}\n",
        "        ],\n",
        "        max_tokens=150\n",
        "    )\n",
        "    return response.choices[0].message['content'].strip()\n",
        "\n",
        "def answer_query(pdf_path, openai_api_key, query):      #This code snippet is used to extract text from a PDF, retrieve the most relevant sections based on a query, generate an answer using the OpenAI API with the relevant context, and return both the context and the generated answer.\n",
        "    text = extract_text_from_pdf(pdf_path)\n",
        "    relevant_section = retrieve_relevant_section(text, query)\n",
        "    context = \" \".join(relevant_section)\n",
        "    answer = generate_answer(openai_api_key, query, context)\n",
        "    return context, answer\n",
        "\n",
        "\n",
        "pdf_path = \"/content/Onepane[27].pdf\"\n",
        "#openai_api_key = \"\"\n",
        "query = \"why onepane?\"  #User input\n",
        "context, answer = answer_query(pdf_path, openai_api_key, query)\n",
        "\n",
        "print(f\"Retrieved Content: {context}\") #Prints the retrieved content from the pdf\n",
        "print(f\"Answer: {answer}\") #Prints the generated answer using the LLM model (GPT3.5) and pdf.\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
